# Хакеры в голове: как мы сами создаем дыры в безопасности

![preview](./preview.jpg)

Информационная безопасность — это не только настройка средств защиты, расстановка гейтов на пайплайн или управление доступом. Серьёзные уязвимости часто скрываются не в коде или архитектуре, а в сознании людей, настраивающих системы и принимающих решения, как ими управлять. В результате почти 90% утечек данных происходит из-за человеческого фактора, а когнитивные искажения — одна из ключевых причин. Разберём, что это за искажения и чем они чреваты.

Алексей Хандожко занимается информационной безопасностью больше 10 лет — методологией, аналитикой, построением архитектуры и управлением процессами. Улучшая процессы ИБ, он часто сталкивался с пониманием безопасности исключительно как внешнего требования, которое надо формально соблюсти. Но такой подход крайне неэффективен. Прибегать к нему — рисковать навлечь на себя угрозу.

В этой статье он не просто перечислил для нас когнитивные искажения, но и показал, к чему они приводят. И предложил практические стратегии, как эти искажения предотвращать.

## Что такое когнитивные искажения и почему они возникают
Когнитивные искажения — это систематические ошибки мышления, которые влияют на принятие решений. Они проявляются, когда наше восприятие искажено предвзятостями, стереотипами или просто устоявшимися привычками. В обычной жизни когнитивные искажения могут быть безобидными, но в информационной безопасности — становятся уязвимостями.

Основные причины когнитивных искажений

**1. Эмоции.** Наши эмоции влияют на восприятие. Например, администратор однажды воспринял false positive событие как реальную атаку. Получив этот опыт, он может и дальше распознавать в качестве атаки ложные срабатывания системы и верить, что угроза действительно была — даже если подтверждений этому нет.

**2. Ограниченное время и перегруженность информацией.** В условиях высокой рабочей нагрузки, специалисты вынуждены принимать решения быстро. Когнитивные искажения подбрасывают нам «короткие пути», которые не всегда безопасны. Каждый человек в условиях перегрузки неосознанно стремится сэкономить когнитивный ресурс — не напрягаться там, где этого можно избежать. Если пойти у этого искажения на поводу, можно подставить подножку самому себе и нарваться на большие проблемы. Важно отслеживать, когда действительно можно сэкономить усилия без последствий, а когда этого делать критически нельзя.

**3. Культурные факторы и опыт.** Опыт работы в определённой среде или под влиянием корпоративной культуры прививает нам определённые схемы мышления, которые сложно нарушить. Вовремя отслеживайте, когда действуете по заученным паттернам. Чаще всего следования им действительно не принесёт последствий. Но важно отрефлексировать ситуации, где от привычного нужно отказаться.

## Наиболее распространенные когнитивные искажения в информационной безопасности
Я обобщил опыт управления процессами безопасности и выделил искажения, чаще всего влияющие на кибербезопасников. Для каждого искажения приведу описание, влияние на безопасность, а также конкретные примеры из практики и рекомендации по минимизации последствий.

### 1. Предвзятость подтверждения (Confirmation Bias)

Предвзятость подтверждения — это склонность обращать внимание только на информацию, подтверждающую наши убеждения или гипотезы. И игнорировать ту, которая их опровергает.

Почему это опасно? Специалист, убежденный, что его система безопасности надёжна, порой не замечает предупреждающие сигналы, интерпретирует их как незначительные отклонения. Это создаёт «слепые пятна», которые злоумышленники используют для атак.

Специалисты SOC особенно часто с этим сталкиваются. Однажды один из инженеров первой линии проигнорировал сигналы о подозрительно сетевом трафике, полагая, что это очередное ложное срабатывание. В то время в компании только строился процесс управления и реагирования на алерты. Ложные срабатывания считались обычным явлением. Но именно в тот день из-за эффекта предвзятости подтверждения атаку не обнаружили своевременно, что привело к утечке данных.

Злую шутку это искажение может сыграть и с пентестерами. Они, стремясь подтвердить свои гипотезы, часто сосредотачиваются на поиске известных уязвимостей, игнорируя другие «низко висящие фрукты». В результате есть риск упустить новые или нестандартные угрозы.

**Как с этим бороться?** В одной из компаний, где я работал, регулярно проводили «игры адвоката дьявола». Это когда одна часть команды ищет способы опровергнуть предположения другой. И хотя порой на таких встречах «летают молнии», этот опыт поможет не попасть в ловушку поиска подтверждения своей правоты и «притягивания фактов за уши».

### 2. Эффект сверхуверенности (Overconfidence Bias)
Люди часто считают, что обладают более глубокими знаниями и навыками, чем это есть на самом деле. Излишняя уверенность заставляет пропускать обновления и отказываться от регулярных проверок безопасности. Часто инженеры считают, что знают свою систему в совершенстве, а значит, она защищена «от и до».

Так решили в одной компании — мол,  текущая система защиты от фишинга и так достаточно сильна. А значит ни к чему вводить дополнительные меры, такие как обучение сотрудников или усиленные фильтры спама. Сотрудникам казалось, что они уже сделали всё возможное для предотвращения фишинга. В этом убеждении основывались на опыте, ведь крупных инцидентов ни разу не случалось — на лицо «ошибка выжившего». 

Но не стоит забывать, что атакующие всегда на шаг впереди — вспомните только, сколько новостей о новых схемах «развода» мошенниками вы встречали за последние полгода.
Как с этим бороться? Внедрите обязательные внешние проверки и аудит, чтобы периодически проверять специалистов — имеет ли реальные основания их убеждённость в собственных силах. Сторонние эксперты смогут обнаружить уязвимости, которые команда упускает. Ведь взгляд «со стороны» — не зашорен и потому более объективен.

### 3. Слепое пятно предубеждения (Blind Spot Bias)
Слепое пятно предубеждения— это склонность считать, что только другие люди подвержены когнитивным искажениям, а мы сами — свободны от предвзятости.

Из-за этого искажения руководители и специалисты могут игнорировать собственные ошибки. До сих пор остаются компании, где соблюдается строгая субординация, а выслуга лет — имеет значение. Часто в таких компаниях руководитель отдела безопасности — бывший сотрудник органов, для которого ничего не стоит проигнорировать замечания младших сотрудников о проблемах и «дырах». Он полагает, что причина замечаний — в неопытности, а его мудрость и опыт — ошибаться не могут.

**Как с этим бороться?** Поощряйте культуру обратной связи и критического мышления, когда каждый член команды может подвергнуть сомнению решения других. На это влияет и сплочённость коллектива, и неформальные мероприятия. В зависимости от размеров команды безопасников, устраивайте регулярные встречи по обмену опытом или просто рассказами о себе. Или введите традиции вроде особого посвящения для новичков. Всё это поможет снизить аффекты слепого пятна.

### 4. Эффект якоря (Anchoring Bias)
Эффект якоря — это склонность полагаться на первую информацию, полученную при принятии решения. Так, первая гипотеза, даже если она ошибочна, может стать якорем, на который опирается вся команда.

На заре своей карьеры я дежурил в выходной – следил, чтобы оборудование нормально запустилось после планового отключения питания в здании. Всё прошло отлично, я проверил работоспособность сервисов и пошёл домой. Спустя несколько дней мы заметили странное — один из серверов начал самопроизвольно выключаться. Сразу подумали о неисправности и отдали блок питания на диагностику — всё работало корректно. Начали искать проблемы с проводкой и бесперебойниками – ничего. А потом я вспомнил, что перед плановым отключением питания создал в панели управления сервером задание на отключение – и оставил его. Конечно, никто не мог такого предположить, поэтому мы сосредоточились на «железных» проблемах вместо обзора всех вариантов.

**Как с этим бороться?** Чтобы избежать «якоря», можно использовать подход «доказательства противоречат якорю». Это когда команда перепроверяет свои выводы и старается найти данные, опровергающие первоначальную гипотезу.

### 5. Эффект статус-кво (Status Quo Bias)
Люди склонны избегать изменений и предпочитают оставаться в привычной зоне комфорта. Многим компаниям сложно отказаться от устаревших методов защиты, на которые потрачено много ресурсов и времени. Но это делает их уязвимыми перед новыми типами угроз.

Команда безопасности продолжала использовать старые алгоритмы шифрования, так как переход на новый протокол казался слишком сложным. В результате, компания оказалась уязвима для современных атак.

**Как с этим бороться?** Регулярно пересматривайте политику безопасности компании и обновляйте её в соответствии с новыми стандартами, устраняя «привычные» методы, которые больше не работают. Можно в течение года собирать заметки о том, какие именно изменения в какой документ надо внести, а потом, в конце года, выделить время для анализа и обновления текстов.

### 6. Эффект ореола (Halo effect)
Эффект ореола — результат воздействия общего впечатления о чём-либо, явлении, человеке, вещи — на восприятие его частных особенностей. Например, репутация поставщика или популярность продукта создают ложное ощущение безопасности. 

Представьте, вы приглашаете компанию провести демо, а там всё хорошо и красиво. Отличный бэклог, удовлетворение всех потребностей и, самое главное, — наличие тёмной темы в дизайне :) Как после этого не купить? Но с началом эксплуатации вы сталкиваетесь с проблемами настройки, долгой обработкой заявок и отсутствием обновлений.

**Как с этим бороться?** Каждое решение нужно оценивать по объективным критериям, независимо от его популярности и репутации. Старайтесь проводить пилоты, рассматривать несколько вариантов и выбирать подходящий для каждого конкретного случая.

### 7. Ошибка выжившего (Survivorship bias)
Во время Второй мировой войны союзники анализировали повреждения возвращающихся с боевых заданий бомбардировщиков, усиливая наиболее пострадавшие участки. Однако такой подход не повышал выживаемость самолётов, поскольку не учитывал состояния тех из них, которые не возвращались. Как раз отсутствие повреждений в определённых зонах у вернувшихся самолетов указывало на критические уязвимости, которые следовало устранить.

В безопасности это искажение проявляется похоже: отсутствие данных воспринимают как отсутствие проблем. Но если в журнал компонента или системы не поступают новые события, это может означать не отсутствие атак, а недостаточную защиту или мониторинг. Резкое снижение объёма данных от группы компонентов может свидетельствовать о сбое в системе обнаружения или о том, что злоумышленники нашли способ обхода защитных механизмов.

**Как с этим бороться?** Важно настраивать алерты не только на сами события, но и на их отсутствие. И это касается не только технических тем – сюда же можно отнести метрики по фишингу или прохождению тестов по безопасности.

## Эффект ретроспективного искажения (Hindsight Bias)
Когда событие уже произошло, людям часто кажется — они могли предсказать исход ситуации. Просто не обращали должного внимания на риски или признаки угроз. Но в реальности люди часто склонны переоценивать свою способность предсказать события в моменте.

Я был свидетелем утечки данных по такой схеме: злоумышленники получили доступ к бэкапам сайтов хостинга. А в бэкапе были персональные данные потенциальных клиентов. Конечно, когда схему раскрутили, всем стало очевидно: и хостинг-провайдер — из списка ненадёжных (уже были утечки), и не уделялось должное внимание защите собираемых данных, и недостаточно надёжно выбран поставщик услуг. Но, тем не менее, до инцидента мало кто мог предположить такой исход.

Подобная ситуация порождает нереалистичные ожидания в будущем: сотрудники и руководители начинают воспринимать угрозы как «очевидные» и недооценивать риски, которые не были «так легко» предсказуемы. Поэтому так важно обращать внимание на все, даже самые неочевидные угрозы.

Когнитивные искажения — это эволюционные механизмы, сформировавшиеся на протяжении тысячелетий, чтобы помочь нашему мозгу принимать решения в условиях ограниченности времени и информации. В древние времена человек постоянно сталкивался с угрозами — хищники, голод, враги, неожиданные природные катастрофы. Быстрая реакция, часто на основе интуитивных и неполных данных, была жизненно значима. Так когнитивные искажения стали результатом эволюционного развития.

Однако в современном мире угрозы становятся сложнее. И хотя информации для анализа больше, старые адаптационные механизмы порой мешают нам принимать взвешенные и обоснованные решения. Эволюционно обоснованные искажения подрывают способности к критическому мышлению и объективному анализу. Поэтому важно понимать и уважать эти инстинкты, но в то же время не идти у них на поводу. Вместо этого подходить критично и «отключать тумблер», когда к решению нужно подойти осознанно. Особенно это актуально в информационной безопасности, где решения требуют внимательного подхода и основываются на фактах, а не на интуитивных предположениях.

## Как противодействовать
Дам несколько рекомендаций, как побороть когнитивные искажения и не создавать дыры в безопасности собственными руками:

1. Создавайте культуру открытого обсуждения, в которой все мнения ценны. Важно стимулировать коллег выражать несогласие и задавать вопросы. Первой реакцией на критику обычно становится отрицание. Старайтесь не демонстрировать отрицание явно, а выслушайте мнение человека. Вы можете не соглашаться, но спокойно и аргументированно. А вместо конфликта переводите несогласие в конструктивный спор.

2. Формализуйте процессы принятия решений. Используйте чек-листы для объективной оценки, чтобы принимать решения на основе фактов, а не интуиции.

3. Регулярно обращайтесь к данным и метрикам. Основанное на данных принятие решений снижает ретроспективные искажения. Руководствуйтесь фактами и историей для корректной оценки.
4. Привлекайте внешних экспертов. Пригласите консультантов и пентестеров для проведения аудитов и проверок, чтобы минимизировать влияние внутренних искажений и получить свежий взгляд.
5. Проводите симуляции и ролевые игры, чтобы протестировать различные подходы к решению проблем. Так вы оцените последствия с разных точек зрения.
6. Регулярно меняйте роли сотрудников. Это помогает избежать узких взглядов и позволяет анализировать ситуацию более объективно. Можно ввести дни, когда сотрудники меняются обязанностями или просто рассказывают о них друг другу.
7. Включите в тренинги по безопасности темы, связанные с когнитивными искажениями. Это поможет сотрудникам осознавать их влияние на принятие решений.
8. Проводите обсуждения после инцидентов и важных решений, чтобы выявить предвзятые суждения и улучшить процессы принятия решений в будущем.

**Помните, что когнитивные искажения — это не просто ошибки мышления, а реальные уязвимости, которые ставят под угрозу ваши системы и данные. Признавая их и внедряя методы борьбы, вы снизите риски и предотвратите серьёзные проблемы.***
